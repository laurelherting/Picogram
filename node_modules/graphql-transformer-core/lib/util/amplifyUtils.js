"use strict";
var __assign = (this && this.__assign) || Object.assign || function(t) {
    for (var s, i = 1, n = arguments.length; i < n; i++) {
        s = arguments[i];
        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
            t[p] = s[p];
    }
    return t;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
var _this = this;
Object.defineProperty(exports, "__esModule", { value: true });
var fs = require("fs");
var path = require("path");
var cloudform_types_1 = require("cloudform-types");
var __1 = require("..");
var graphql_transformer_common_1 = require("graphql-transformer-common");
var TRANSFORM_CONFIG_FILE_NAME = "transform.conf.json";
var CLOUDFORMATION_FILE_NAME = 'cloudformation-template.json';
var PARAMETERS_FILE_NAME = 'parameters.json';
function buildProject(opts) {
    return __awaiter(this, void 0, void 0, function () {
        var userProjectConfig, stackMapping, transform, transformOutput, merged;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, readProjectConfiguration(opts.projectDirectory)];
                case 1:
                    userProjectConfig = _a.sent();
                    stackMapping = getStackMappingsFromMigrationConfig(userProjectConfig.config.Migration);
                    transform = new __1.default({
                        transformers: opts.transformers,
                        stackMapping: stackMapping
                    });
                    transformOutput = transform.transform(userProjectConfig.schema.toString());
                    if (userProjectConfig.config && userProjectConfig.config.Migration) {
                        transformOutput = adjustBuildForMigration(transformOutput, userProjectConfig.config.Migration);
                    }
                    merged = mergeUserConfigWithTransformOutput(userProjectConfig, transformOutput);
                    writeDeploymentToDisk(merged, path.join(opts.projectDirectory, 'build'), opts.rootStackFileName);
                    return [2 /*return*/];
            }
        });
    });
}
exports.buildProject = buildProject;
/**
 * Returns a map where the keys are the names of the resources and the values are root.
 * This will be passed to the transform constructor to cause resources from a migration
 * to remain in the top level stack.
 */
function getStackMappingsFromMigrationConfig(migrationConfig) {
    if (migrationConfig && migrationConfig.V1) {
        var resourceIdsToHoist = migrationConfig.V1.Resources || [];
        return resourceIdsToHoist.reduce(function (acc, k) {
            var _a;
            return (__assign({}, acc, (_a = {}, _a[k] = 'root', _a)));
        }, {});
    }
    return {};
}
/**
 * This adjusts a project build to account for the resources created by a previous
 * version of the Amplify CLI. Mainly this prevents the deletion of DynamoDB tables
 * while still allowing the transform to customize that logical resource.
 * @param resources The resources to change.
 * @param idsToHoist The logical ids to hoist into the root of the template.
 */
function adjustBuildForMigration(resources, migrationConfig) {
    if (migrationConfig && migrationConfig.V1) {
        var resourceIdsToHoist = migrationConfig.V1.Resources || [];
        if (resourceIdsToHoist.length === 0) {
            return resources;
        }
        var resourceIdMap = resourceIdsToHoist.reduce(function (acc, k) {
            var _a;
            return (__assign({}, acc, (_a = {}, _a[k] = true, _a)));
        }, {});
        for (var _i = 0, _a = Object.keys(resources.stacks); _i < _a.length; _i++) {
            var stackKey = _a[_i];
            var template = resources.stacks[stackKey];
            for (var _b = 0, _c = Object.keys(template.Resources); _b < _c.length; _b++) {
                var resourceKey = _c[_b];
                if (resourceIdMap[resourceKey]) {
                    // Handle any special detials for migrated details.
                    var resource = template.Resources[resourceKey];
                    template.Resources[resourceKey] = formatMigratedResource(resource);
                }
            }
        }
        var rootStack = resources.rootStack;
        for (var _d = 0, _e = Object.keys(rootStack.Resources); _d < _e.length; _d++) {
            var resourceKey = _e[_d];
            if (resourceIdMap[resourceKey]) {
                // Handle any special detials for migrated details.
                var resource = rootStack.Resources[resourceKey];
                rootStack.Resources[resourceKey] = formatMigratedResource(resource);
            }
        }
    }
    return resources;
}
/**
 * Merge user config on top of transform output when needed.
 */
function mergeUserConfigWithTransformOutput(userConfig, transformOutput) {
    // Override user defined resolvers.
    var userResolvers = userConfig.resolvers || {};
    var transformResolvers = transformOutput.resolvers;
    for (var _i = 0, _a = Object.keys(userResolvers); _i < _a.length; _i++) {
        var userResolver = _a[_i];
        transformResolvers[userResolver] = userConfig.resolvers[userResolver];
    }
    // Override user defined stacks.
    var userStacks = userConfig.stacks || {};
    var transformStacks = transformOutput.stacks;
    var rootStack = transformOutput.rootStack;
    // Get all the transform stacks. Custom stacks will depend on all of them
    // so they can always access data sources created by the transform.
    var resourceTypesToDependOn = {
        "AWS::CloudFormation::Stack": true,
        "AWS::AppSync::GraphQLApi": true,
        "AWS::AppSync::GraphQLSchema": true,
    };
    var allResourceIds = Object.keys(rootStack.Resources).filter(function (k) {
        var resource = rootStack.Resources[k];
        return resourceTypesToDependOn[resource.Type];
    });
    var parametersKeys = Object.keys(rootStack.Parameters);
    var customStackParams = parametersKeys.reduce(function (acc, k) {
        var _a;
        return (__assign({}, acc, (_a = {}, _a[k] = cloudform_types_1.Fn.Ref(k), _a)));
    }, {});
    customStackParams[graphql_transformer_common_1.ResourceConstants.PARAMETERS.AppSyncApiId] = cloudform_types_1.Fn.GetAtt(graphql_transformer_common_1.ResourceConstants.RESOURCES.GraphQLAPILogicalID, 'ApiId');
    for (var _b = 0, _c = Object.keys(userStacks); _b < _c.length; _b++) {
        var userStack = _c[_b];
        if (transformOutput.stacks[userStack]) {
            throw new Error("You cannot provide a stack named " + userStack + " as it             will be overwritten by a stack generated by the GraphQL Transform.");
        }
        var userDefinedStack = userConfig.stacks[userStack];
        // Providing a parameter value when the parameters is not explicitly defined
        // in the template causes CloudFormation to throw and error. This will only
        // provide the value to the nested stack if the user has specified it.
        var parametersForStack = Object.keys(userDefinedStack.Parameters).reduce(function (acc, k) {
            var _a;
            return (__assign({}, acc, (_a = {}, _a[k] = customStackParams[k], _a)));
        }, {});
        transformStacks[userStack] = userDefinedStack;
        // Split on non alphabetic characters to make a valid resource id.
        var stackResourceId = userStack.split(/[^A-Za-z]/).join('');
        var customNestedStack = new cloudform_types_1.CloudFormation.Stack({
            Parameters: parametersForStack,
            TemplateURL: cloudform_types_1.Fn.Join('/', [
                "https://s3.amazonaws.com",
                cloudform_types_1.Fn.Ref(graphql_transformer_common_1.ResourceConstants.PARAMETERS.S3DeploymentBucket),
                cloudform_types_1.Fn.Ref(graphql_transformer_common_1.ResourceConstants.PARAMETERS.S3DeploymentRootKey),
                'stacks',
                userStack
            ])
        }).dependsOn(allResourceIds);
        rootStack.Resources[stackResourceId] = customNestedStack;
    }
    return __assign({}, transformOutput, { resolvers: transformResolvers, stacks: transformStacks });
}
function readSchema(projectDirectory) {
    return __awaiter(this, void 0, void 0, function () {
        var schemaFilePath, schemaDirectoryPath, schemaFileExists, schemaDirectoryExists, schema;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    schemaFilePath = path.join(projectDirectory, 'schema.graphql');
                    schemaDirectoryPath = path.join(projectDirectory, 'schema');
                    return [4 /*yield*/, exists(schemaFilePath)];
                case 1:
                    schemaFileExists = _a.sent();
                    return [4 /*yield*/, exists(schemaDirectoryPath)];
                case 2:
                    schemaDirectoryExists = _a.sent();
                    if (!schemaFileExists) return [3 /*break*/, 4];
                    return [4 /*yield*/, readFile(schemaFilePath)];
                case 3:
                    schema = (_a.sent()).toString();
                    return [3 /*break*/, 7];
                case 4:
                    if (!schemaDirectoryExists) return [3 /*break*/, 6];
                    return [4 /*yield*/, readSchemaDocuments(schemaDirectoryPath)];
                case 5:
                    schema = (_a.sent()).join('\n');
                    return [3 /*break*/, 7];
                case 6: throw new Error("Could not find a schema at " + schemaFilePath);
                case 7: return [2 /*return*/, schema];
            }
        });
    });
}
exports.readSchema = readSchema;
function readProjectConfiguration(projectDirectory) {
    return __awaiter(this, void 0, void 0, function () {
        var schema, resolverDirectory, resolverDirExists, resolvers, resolverFiles, _i, resolverFiles_1, resolverFile, resolverFilePath, _a, _b, stacksDirectory, stacksDirExists, stacks, stackFiles, _c, stackFiles_1, stackFile, stackFilePath, stackBuffer, configPath, configExists, config, configStr;
        return __generator(this, function (_d) {
            switch (_d.label) {
                case 0: return [4 /*yield*/, readSchema(projectDirectory)];
                case 1:
                    schema = _d.sent();
                    resolverDirectory = path.join(projectDirectory, 'resolvers');
                    return [4 /*yield*/, exists(resolverDirectory)];
                case 2:
                    resolverDirExists = _d.sent();
                    resolvers = {};
                    if (!resolverDirExists) return [3 /*break*/, 7];
                    return [4 /*yield*/, readDir(resolverDirectory)];
                case 3:
                    resolverFiles = _d.sent();
                    _i = 0, resolverFiles_1 = resolverFiles;
                    _d.label = 4;
                case 4:
                    if (!(_i < resolverFiles_1.length)) return [3 /*break*/, 7];
                    resolverFile = resolverFiles_1[_i];
                    if (resolverFile.indexOf('.') === 0) {
                        return [3 /*break*/, 6];
                    }
                    resolverFilePath = path.join(resolverDirectory, resolverFile);
                    _a = resolvers;
                    _b = resolverFile;
                    return [4 /*yield*/, readFile(resolverFilePath)];
                case 5:
                    _a[_b] = _d.sent();
                    _d.label = 6;
                case 6:
                    _i++;
                    return [3 /*break*/, 4];
                case 7:
                    stacksDirectory = path.join(projectDirectory, 'stacks');
                    return [4 /*yield*/, exists(stacksDirectory)];
                case 8:
                    stacksDirExists = _d.sent();
                    stacks = {};
                    if (!stacksDirExists) return [3 /*break*/, 13];
                    return [4 /*yield*/, readDir(stacksDirectory)];
                case 9:
                    stackFiles = _d.sent();
                    _c = 0, stackFiles_1 = stackFiles;
                    _d.label = 10;
                case 10:
                    if (!(_c < stackFiles_1.length)) return [3 /*break*/, 13];
                    stackFile = stackFiles_1[_c];
                    if (stackFile.indexOf('.') === 0) {
                        return [3 /*break*/, 12];
                    }
                    stackFilePath = path.join(stacksDirectory, stackFile);
                    throwIfNotJSON(stackFile);
                    return [4 /*yield*/, readFile(stackFilePath)];
                case 11:
                    stackBuffer = _d.sent();
                    try {
                        stacks[stackFile] = JSON.parse(stackBuffer.toString());
                    }
                    catch (e) {
                        throw new Error("The CloudFormation template " + stackFiles + " does not contain valid JSON.");
                    }
                    _d.label = 12;
                case 12:
                    _c++;
                    return [3 /*break*/, 10];
                case 13:
                    configPath = path.join(projectDirectory, TRANSFORM_CONFIG_FILE_NAME);
                    return [4 /*yield*/, exists(configPath)];
                case 14:
                    configExists = _d.sent();
                    config = {};
                    if (!configExists) return [3 /*break*/, 16];
                    return [4 /*yield*/, readFile(configPath)];
                case 15:
                    configStr = _d.sent();
                    config = JSON.parse(configStr.toString());
                    _d.label = 16;
                case 16: return [2 /*return*/, {
                        stacks: stacks,
                        resolvers: resolvers,
                        schema: schema,
                        config: config
                    }];
            }
        });
    });
}
exports.readProjectConfiguration = readProjectConfiguration;
function throwIfNotJSON(stackFile) {
    var nameParts = stackFile.split('.');
    var extension = nameParts[nameParts.length - 1];
    if (extension === "yaml" || extension === "yml") {
        throw new Error("Yaml is not yet supported. Please convert the CloudFormation stack " + stackFile + " to json.");
    }
    if (extension !== "json") {
        throw new Error("Invalid extension ." + extension + " for stack " + stackFile);
    }
}
/**
 * Reads deployment assets from disk and uploads to the cloud via an uploader.
 * @param opts Deployment options.
 */
function uploadDeployment(opts) {
    return __awaiter(this, void 0, void 0, function () {
        var e_1;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    _a.trys.push([0, 2, , 3]);
                    if (!opts.directory) {
                        throw new Error("You must provide a 'directory'");
                    }
                    else if (!fs.existsSync(opts.directory)) {
                        throw new Error("Invalid 'directory': directory does not exist at " + opts.directory);
                    }
                    if (!opts.upload || typeof opts.upload !== 'function') {
                        throw new Error("You must provide an 'upload' function");
                    }
                    return [4 /*yield*/, uploadDirectory(opts)];
                case 1:
                    _a.sent();
                    return [3 /*break*/, 3];
                case 2:
                    e_1 = _a.sent();
                    throw e_1;
                case 3: return [2 /*return*/];
            }
        });
    });
}
exports.uploadDeployment = uploadDeployment;
/**
 * Uploads a file with exponential backoff up to a point.
 * @param opts The deployment options
 * @param key The bucket key
 * @param body The blob body as a buffer
 * @param backoffMS The time to wait this invocation
 * @param numTries The max number of tries
 */
function uploadFile(opts, key, body, backoffMS, numTries) {
    if (backoffMS === void 0) { backoffMS = 1000; }
    if (numTries === void 0) { numTries = 5; }
    return __awaiter(this, void 0, void 0, function () {
        var e_2;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    _a.trys.push([0, 2, , 6]);
                    return [4 /*yield*/, opts.upload({
                            Key: key,
                            Body: body
                        })];
                case 1: return [2 /*return*/, _a.sent()];
                case 2:
                    e_2 = _a.sent();
                    if (!(numTries > 1)) return [3 /*break*/, 5];
                    return [4 /*yield*/, new Promise(function (res, rej) { return setTimeout(function () { return res(); }, backoffMS); })];
                case 3:
                    _a.sent();
                    return [4 /*yield*/, uploadFile(opts, key, body, backoffMS * 2, numTries - 1)];
                case 4:
                    _a.sent();
                    _a.label = 5;
                case 5: throw e_2;
                case 6: return [2 /*return*/];
            }
        });
    });
}
function uploadDirectory(opts, key) {
    if (key === void 0) { key = ''; }
    return __awaiter(this, void 0, void 0, function () {
        var files, _i, files_1, file, resourcePath, uploadKey, isDirectory, resourceContents;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, readDir(opts.directory)];
                case 1:
                    files = _a.sent();
                    _i = 0, files_1 = files;
                    _a.label = 2;
                case 2:
                    if (!(_i < files_1.length)) return [3 /*break*/, 9];
                    file = files_1[_i];
                    resourcePath = path.join(opts.directory, file);
                    uploadKey = path.posix.join(key, file);
                    return [4 /*yield*/, lstat(resourcePath)];
                case 3:
                    isDirectory = (_a.sent()).isDirectory();
                    if (!isDirectory) return [3 /*break*/, 5];
                    return [4 /*yield*/, uploadDirectory(__assign({}, opts, { directory: resourcePath }), uploadKey)];
                case 4:
                    _a.sent();
                    return [3 /*break*/, 8];
                case 5: return [4 /*yield*/, readFile(resourcePath)];
                case 6:
                    resourceContents = _a.sent();
                    return [4 /*yield*/, uploadFile(opts, uploadKey, resourceContents)];
                case 7:
                    _a.sent();
                    _a.label = 8;
                case 8:
                    _i++;
                    return [3 /*break*/, 2];
                case 9: return [2 /*return*/];
            }
        });
    });
}
function emptyDirectory(directory) {
    var files = fs.readdirSync(directory);
    for (var _i = 0, files_2 = files; _i < files_2.length; _i++) {
        var file = files_2[_i];
        var resourcePath = path.join(directory, file);
        var isDirectory = fs.lstatSync(resourcePath).isDirectory();
        if (isDirectory) {
            emptyDirectory(resourcePath);
        }
        else {
            fs.unlinkSync(resourcePath);
        }
    }
}
/**
 * Writes a deployment to disk at a path.
 */
function writeDeploymentToDisk(deployment, directory, rootStackFileName) {
    if (rootStackFileName === void 0) { rootStackFileName = 'rootStack.json'; }
    // Delete the last deployments resources.
    emptyDirectory(directory);
    // Write the schema to disk
    var schema = deployment.schema;
    var fullSchemaPath = path.normalize(directory + "/schema.graphql");
    fs.writeFileSync(fullSchemaPath, schema);
    // Setup the directories if they do not exist.
    initStacksAndResolversDirectories(directory);
    // Write resolvers to disk
    var resolverFileNames = Object.keys(deployment.resolvers);
    var resolverRootPath = path.normalize(directory + "/resolvers");
    for (var _i = 0, resolverFileNames_1 = resolverFileNames; _i < resolverFileNames_1.length; _i++) {
        var resolverFileName = resolverFileNames_1[_i];
        var fullResolverPath = path.normalize(resolverRootPath + '/' + resolverFileName);
        fs.writeFileSync(fullResolverPath, deployment.resolvers[resolverFileName]);
    }
    // Write the stacks to disk
    var stackNames = Object.keys(deployment.stacks);
    var stackRootPath = path.normalize(directory + "/stacks");
    for (var _a = 0, stackNames_1 = stackNames; _a < stackNames_1.length; _a++) {
        var stackFileName = stackNames_1[_a];
        var fileNameParts = stackFileName.split('.');
        if (fileNameParts.length === 1) {
            fileNameParts.push('json');
        }
        var fullFileName = fileNameParts.join('.');
        throwIfNotJSON(fullFileName);
        var fullStackPath = path.normalize(stackRootPath + '/' + fullFileName);
        var stackString = deployment.stacks[stackFileName];
        stackString = typeof stackString === 'string' ? deployment.stacks[stackFileName] : JSON.stringify(deployment.stacks[stackFileName], null, 4);
        fs.writeFileSync(fullStackPath, stackString);
    }
    // Write any functions to disk
    var functionNames = Object.keys(deployment.functions);
    var functionRootPath = path.normalize(directory + "/functions");
    if (!fs.existsSync(functionRootPath)) {
        fs.mkdirSync(functionRootPath);
    }
    for (var _b = 0, functionNames_1 = functionNames; _b < functionNames_1.length; _b++) {
        var functionName = functionNames_1[_b];
        var fullFunctionPath = path.normalize(functionRootPath + '/' + functionName);
        var zipContents = fs.readFileSync(deployment.functions[functionName]);
        fs.writeFileSync(fullFunctionPath, zipContents);
    }
    var rootStack = deployment.rootStack;
    var rootStackPath = path.normalize(directory + ("/" + rootStackFileName));
    fs.writeFileSync(rootStackPath, JSON.stringify(rootStack, null, 4));
}
function readSchemaDocuments(schemaDirectoryPath) {
    return __awaiter(this, void 0, void 0, function () {
        var files, schemaDocuments, _i, files_3, fileName, fullPath, stats, childDocs, schemaDoc;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, readDir(schemaDirectoryPath)];
                case 1:
                    files = _a.sent();
                    schemaDocuments = [];
                    _i = 0, files_3 = files;
                    _a.label = 2;
                case 2:
                    if (!(_i < files_3.length)) return [3 /*break*/, 8];
                    fileName = files_3[_i];
                    if (fileName.indexOf('.') === 0) {
                        return [3 /*break*/, 7];
                    }
                    fullPath = schemaDirectoryPath + "/" + fileName;
                    return [4 /*yield*/, lstat(fullPath)];
                case 3:
                    stats = _a.sent();
                    if (!stats.isDirectory()) return [3 /*break*/, 5];
                    return [4 /*yield*/, readSchemaDocuments(fullPath)];
                case 4:
                    childDocs = _a.sent();
                    schemaDocuments = schemaDocuments.concat(childDocs);
                    return [3 /*break*/, 7];
                case 5:
                    if (!stats.isFile()) return [3 /*break*/, 7];
                    return [4 /*yield*/, readFile(fullPath)];
                case 6:
                    schemaDoc = _a.sent();
                    schemaDocuments.push(schemaDoc);
                    _a.label = 7;
                case 7:
                    _i++;
                    return [3 /*break*/, 2];
                case 8: return [2 /*return*/, schemaDocuments];
            }
        });
    });
}
function deleteDirectory(directory) {
    return __awaiter(this, void 0, void 0, function () {
        var pathExists, dirStats, files, _i, files_4, fileName, fullPath, stats;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, exists(directory)];
                case 1:
                    pathExists = _a.sent();
                    if (!pathExists) {
                        return [2 /*return*/];
                    }
                    return [4 /*yield*/, lstat(directory)];
                case 2:
                    dirStats = _a.sent();
                    if (!dirStats.isDirectory()) {
                        return [2 /*return*/];
                    }
                    return [4 /*yield*/, readDir(directory)];
                case 3:
                    files = _a.sent();
                    _i = 0, files_4 = files;
                    _a.label = 4;
                case 4:
                    if (!(_i < files_4.length)) return [3 /*break*/, 10];
                    fileName = files_4[_i];
                    fullPath = path.join(directory, fileName);
                    return [4 /*yield*/, lstat(fullPath)];
                case 5:
                    stats = _a.sent();
                    if (!stats.isDirectory()) return [3 /*break*/, 7];
                    return [4 /*yield*/, deleteDirectory(fullPath)];
                case 6:
                    _a.sent();
                    return [3 /*break*/, 9];
                case 7:
                    if (!stats.isFile()) return [3 /*break*/, 9];
                    return [4 /*yield*/, unlink(fullPath)];
                case 8:
                    _a.sent();
                    _a.label = 9;
                case 9:
                    _i++;
                    return [3 /*break*/, 4];
                case 10: return [4 /*yield*/, rmdir(directory)];
                case 11:
                    _a.sent();
                    return [2 /*return*/];
            }
        });
    });
}
function mkdirIfNone(dir) {
    return __awaiter(this, void 0, void 0, function () {
        var pathExists;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, exists(dir)];
                case 1:
                    pathExists = _a.sent();
                    if (!pathExists) {
                        fs.mkdirSync(dir);
                    }
                    return [2 /*return*/];
            }
        });
    });
}
function writeToPath(directory, obj) {
    return __awaiter(this, void 0, void 0, function () {
        var i, newDir, _i, _a, key, newDir;
        return __generator(this, function (_b) {
            switch (_b.label) {
                case 0:
                    if (!Array.isArray(obj)) return [3 /*break*/, 6];
                    return [4 /*yield*/, mkdirIfNone(directory)];
                case 1:
                    _b.sent();
                    i = 0;
                    _b.label = 2;
                case 2:
                    if (!(i < obj.length)) return [3 /*break*/, 5];
                    newDir = path.join(directory, "" + i);
                    return [4 /*yield*/, writeToPath(newDir, obj[i])];
                case 3:
                    _b.sent();
                    _b.label = 4;
                case 4:
                    i++;
                    return [3 /*break*/, 2];
                case 5: return [3 /*break*/, 13];
                case 6:
                    if (!(typeof obj === 'object')) return [3 /*break*/, 12];
                    return [4 /*yield*/, mkdirIfNone(directory)];
                case 7:
                    _b.sent();
                    _i = 0, _a = Object.keys(obj);
                    _b.label = 8;
                case 8:
                    if (!(_i < _a.length)) return [3 /*break*/, 11];
                    key = _a[_i];
                    newDir = path.join(directory, key);
                    return [4 /*yield*/, writeToPath(newDir, obj[key])];
                case 9:
                    _b.sent();
                    _b.label = 10;
                case 10:
                    _i++;
                    return [3 /*break*/, 8];
                case 11: return [3 /*break*/, 13];
                case 12:
                    if (typeof obj === 'string') {
                        fs.writeFileSync(directory, obj);
                    }
                    _b.label = 13;
                case 13: return [2 /*return*/];
            }
        });
    });
}
function readFromPath(directory) {
    return __awaiter(this, void 0, void 0, function () {
        var pathExists, dirStats, buf, files, accum, _i, files_5, fileName, fullPath, value;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, exists(directory)];
                case 1:
                    pathExists = _a.sent();
                    if (!pathExists) {
                        return [2 /*return*/];
                    }
                    return [4 /*yield*/, lstat(directory)];
                case 2:
                    dirStats = _a.sent();
                    if (!!dirStats.isDirectory()) return [3 /*break*/, 4];
                    return [4 /*yield*/, readFile(directory)];
                case 3:
                    buf = _a.sent();
                    return [2 /*return*/, buf.toString()];
                case 4: return [4 /*yield*/, readDir(directory)];
                case 5:
                    files = _a.sent();
                    accum = {};
                    _i = 0, files_5 = files;
                    _a.label = 6;
                case 6:
                    if (!(_i < files_5.length)) return [3 /*break*/, 9];
                    fileName = files_5[_i];
                    fullPath = path.join(directory, fileName);
                    return [4 /*yield*/, readFromPath(fullPath)];
                case 7:
                    value = _a.sent();
                    accum[fileName] = value;
                    _a.label = 8;
                case 8:
                    _i++;
                    return [3 /*break*/, 6];
                case 9: return [2 /*return*/, accum];
            }
        });
    });
}
function clearAtPath(clearPath) {
    return __awaiter(this, void 0, void 0, function () {
        var pathExists, dirStats;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, exists(clearPath)];
                case 1:
                    pathExists = _a.sent();
                    if (!pathExists) return [3 /*break*/, 6];
                    return [4 /*yield*/, lstat(clearPath)];
                case 2:
                    dirStats = _a.sent();
                    if (!dirStats.isDirectory()) return [3 /*break*/, 4];
                    return [4 /*yield*/, deleteDirectory(clearPath)];
                case 3:
                    _a.sent();
                    return [3 /*break*/, 6];
                case 4: return [4 /*yield*/, unlink(clearPath)];
                case 5:
                    _a.sent();
                    _a.label = 6;
                case 6: return [2 /*return*/];
            }
        });
    });
}
/**
 * Using the current cloudbackend as the source of truth of the current env,
 * move the deployment forward to the intermediate stage before allowing the
 * rest of the deployment to take place.
 * @param opts
 */
function migrateAPIProject(opts) {
    return __awaiter(this, void 0, void 0, function () {
        var projectDirectory, cloudBackendDirectory, copyOfCloudBackend, projectConfig, cloudBackendConfig, transformConfig;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    projectDirectory = opts.projectDirectory;
                    cloudBackendDirectory = opts.cloudBackendDirectory || projectDirectory;
                    return [4 /*yield*/, readFromPath(cloudBackendDirectory)];
                case 1:
                    copyOfCloudBackend = _a.sent();
                    if (copyOfCloudBackend.build && !copyOfCloudBackend.build[CLOUDFORMATION_FILE_NAME]) {
                        copyOfCloudBackend.build[CLOUDFORMATION_FILE_NAME] = copyOfCloudBackend[CLOUDFORMATION_FILE_NAME];
                    }
                    return [4 /*yield*/, readFromPath(projectDirectory)];
                case 2:
                    projectConfig = _a.sent();
                    return [4 /*yield*/, readV1ProjectConfiguration(cloudBackendDirectory)];
                case 3:
                    cloudBackendConfig = _a.sent();
                    transformConfig = makeTransformConfigFromOldProject(cloudBackendConfig);
                    return [4 /*yield*/, updateToIntermediateProject(projectDirectory, cloudBackendConfig, transformConfig)];
                case 4:
                    _a.sent();
                    // Return the old project structures in case of revert.
                    return [2 /*return*/, {
                            project: projectConfig,
                            cloudBackend: copyOfCloudBackend
                        }];
            }
        });
    });
}
exports.migrateAPIProject = migrateAPIProject;
function revertAPIMigration(directory, oldProject) {
    return __awaiter(this, void 0, void 0, function () {
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, clearAtPath(directory)];
                case 1:
                    _a.sent();
                    return [4 /*yield*/, writeToPath(directory, oldProject)];
                case 2:
                    _a.sent();
                    return [2 /*return*/];
            }
        });
    });
}
exports.revertAPIMigration = revertAPIMigration;
/**
 * Read the configuration for the old version of amplify CLI.
 */
function readV1ProjectConfiguration(projectDirectory) {
    return __awaiter(this, void 0, void 0, function () {
        var schema, cloudFormationTemplatePath, cloudFormationTemplateExists, cloudFormationTemplateStr, cloudFormationTemplate, parametersFilePath, parametersFileExists, parametersFileStr, parametersFile;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, readSchema(projectDirectory)];
                case 1:
                    schema = _a.sent();
                    cloudFormationTemplatePath = path.join(projectDirectory, CLOUDFORMATION_FILE_NAME);
                    return [4 /*yield*/, exists(cloudFormationTemplatePath)];
                case 2:
                    cloudFormationTemplateExists = _a.sent();
                    if (!cloudFormationTemplateExists) {
                        throw new Error("Could not find cloudformation template at " + cloudFormationTemplatePath);
                    }
                    return [4 /*yield*/, readFile(cloudFormationTemplatePath)];
                case 3:
                    cloudFormationTemplateStr = _a.sent();
                    cloudFormationTemplate = JSON.parse(cloudFormationTemplateStr.toString());
                    parametersFilePath = path.join(projectDirectory, 'parameters.json');
                    return [4 /*yield*/, exists(parametersFilePath)];
                case 4:
                    parametersFileExists = _a.sent();
                    if (!parametersFileExists) {
                        throw new Error("Could not find parameters.json at " + parametersFilePath);
                    }
                    return [4 /*yield*/, readFile(parametersFilePath)];
                case 5:
                    parametersFileStr = _a.sent();
                    parametersFile = JSON.parse(parametersFileStr.toString());
                    return [2 /*return*/, {
                            template: cloudFormationTemplate,
                            parameters: parametersFile,
                            schema: schema
                        }];
            }
        });
    });
}
exports.readV1ProjectConfiguration = readV1ProjectConfiguration;
function makeTransformConfigFromOldProject(project) {
    var migrationResourceIds = [];
    for (var _i = 0, _a = Object.keys(project.template.Resources); _i < _a.length; _i++) {
        var key = _a[_i];
        var resource = project.template.Resources[key];
        switch (resource.Type) {
            case 'AWS::DynamoDB::Table': {
                migrationResourceIds.push(key);
                // When searchable is used we need to keep the output stream arn
                // output at the top level as well. TODO: Only do this when searchable is enabled.
                // migrationOutputIds.push(`GetAtt${key}StreamArn`);
                break;
            }
            case 'AWS::Elasticsearch::Domain': {
                migrationResourceIds.push(key);
                break;
            }
            case 'AWS::IAM::Role': {
                if (key === 'ElasticSearchAccessIAMRole') {
                    // A special case for deploying the migration to projects with @searchable.
                    // This keeps an IAM role needed by the old ES policy document around.
                    migrationResourceIds.push(key);
                }
                break;
            }
            default: {
                break;
            }
        }
    }
    // for (const key of Object.keys(project.template.Outputs)) {
    //     // Pull any outputs that reference a hoisted id.
    //     const output = project.template.Outputs[key];
    //     const outputValue = output.Value;
    //     let refdId;
    //     if (outputValue["Fn::GetAtt"]) {
    //         refdId = outputValue["Fn::GetAtt"][0];
    //     } else if (outputValue["Fn::Ref"]) {
    //         refdId = outputValue["Fn::Ref"];
    //     }
    //     if (refdId && migrationResourceIds.find(id => id === refdId)) {
    //         migrationOutputIds.push(key);
    //     }
    // }
    return {
        Migration: {
            V1: {
                Resources: migrationResourceIds
            }
        }
    };
}
exports.makeTransformConfigFromOldProject = makeTransformConfigFromOldProject;
function formatMigratedResource(obj) {
    var jsonNode = obj && typeof obj.toJSON === 'function' ? obj.toJSON() : obj;
    // const withReplacedReferences = replaceReferencesForMigration(obj);
    var withoutEncryption = removeSSE(jsonNode);
    return withoutEncryption;
}
function removeSSE(resource) {
    if (resource && resource.Properties && resource.Properties.SSESpecification) {
        delete resource.Properties.SSESpecification;
    }
    return resource;
}
/**
 * Walks the object and replaces the offending Ref with the correct GetAtt
 * as is required by the migration tool.
 */
function replaceReferencesForMigration(obj) {
    var jsonNode = obj && typeof obj.toJSON === 'function' ? obj.toJSON() : obj;
    if (Array.isArray(jsonNode)) {
        for (var i = 0; i < jsonNode.length; i++) {
            var replaced = formatMigratedResource(jsonNode[i]);
            jsonNode[i] = replaced;
        }
        return jsonNode;
    }
    else if (typeof jsonNode === 'object') {
        var ref = jsonNode.Ref || jsonNode['Fn::Ref'];
        if (ref && ref === 'GetAttGraphQLAPIApiId') {
            return {
                "Fn::GetAtt": [
                    "GraphQLAPI",
                    "ApiId"
                ]
            };
        }
        for (var _i = 0, _a = Object.keys(jsonNode); _i < _a.length; _i++) {
            var key = _a[_i];
            var replaced = formatMigratedResource(jsonNode[key]);
            jsonNode[key] = replaced;
        }
        return jsonNode;
    }
    return jsonNode;
}
/**
 * Updates the project to a temporary configuration that stages the real migration.
 */
function updateToIntermediateProject(projectDirectory, project, config) {
    return __awaiter(this, void 0, void 0, function () {
        var migrationInfoFilePath, filteredResources, _i, _a, key, resource, alteredResource, filteredParameterValues, filteredTemplateParameters, _b, _c, key, param, templateCopy, oldCloudFormationTemplatePath, cloudFormationTemplateOutputPath, parametersInputPath;
        return __generator(this, function (_d) {
            migrationInfoFilePath = path.join(projectDirectory, TRANSFORM_CONFIG_FILE_NAME);
            fs.writeFileSync(migrationInfoFilePath, JSON.stringify(config, null, 4));
            filteredResources = {};
            for (_i = 0, _a = Object.keys(project.template.Resources); _i < _a.length; _i++) {
                key = _a[_i];
                resource = project.template.Resources[key];
                switch (resource.Type) {
                    case 'AWS::DynamoDB::Table':
                    case 'AWS::Elasticsearch::Domain':
                    case 'AWS::AppSync::GraphQLApi':
                    case 'AWS::AppSync::ApiKey':
                    case 'AWS::Cognito::UserPool':
                    case 'AWS::Cognito::UserPoolClient':
                        filteredResources[key] = formatMigratedResource(resource);
                        break;
                    case 'AWS::IAM::Role': {
                        if (key === 'ElasticSearchAccessIAMRole') {
                            // A special case for the ES migration case.
                            filteredResources[key] = resource;
                        }
                        break;
                    }
                    case 'AWS::AppSync::GraphQLSchema':
                        alteredResource = __assign({}, resource);
                        alteredResource.Properties.DefinitionS3Location = {
                            "Fn::Sub": [
                                "s3://${S3DeploymentBucket}/${S3DeploymentRootKey}/schema.graphql",
                                {
                                    "S3DeploymentBucket": {
                                        "Ref": "S3DeploymentBucket"
                                    },
                                    "S3DeploymentRootKey": {
                                        "Ref": "S3DeploymentRootKey"
                                    }
                                }
                            ]
                        };
                        filteredResources[key] = alteredResource;
                        break;
                    default:
                        break; // Everything else will live in a nested stack.
                }
            }
            filteredParameterValues = {
                DynamoDBBillingMode: 'PROVISIONED'
            };
            filteredTemplateParameters = {
                env: {
                    Type: "String",
                    Description: "The environment name. e.g. Dev, Test, or Production",
                    Default: "NONE"
                },
                S3DeploymentBucket: {
                    Type: "String",
                    Description: "The S3 bucket containing all deployment assets for the project."
                },
                S3DeploymentRootKey: {
                    Type: "String",
                    Description: "An S3 key relative to the S3DeploymentBucket that points to the root of the deployment directory."
                }
            };
            for (_b = 0, _c = Object.keys(project.template.Parameters); _b < _c.length; _b++) {
                key = _c[_b];
                switch (key) {
                    case 'ResolverBucket':
                    case 'ResolverRootKey':
                    case 'DeploymentTimestamp':
                    case 'schemaGraphql':
                        break;
                    default: {
                        param = project.template.Parameters[key];
                        filteredTemplateParameters[key] = param;
                        if (project.parameters[key]) {
                            filteredParameterValues[key] = project.parameters[key];
                        }
                        break;
                    }
                }
            }
            templateCopy = __assign({}, project.template, { Resources: filteredResources, Parameters: filteredTemplateParameters });
            oldCloudFormationTemplatePath = path.join(projectDirectory, CLOUDFORMATION_FILE_NAME);
            if (fs.existsSync(oldCloudFormationTemplatePath)) {
                fs.unlinkSync(oldCloudFormationTemplatePath);
            }
            cloudFormationTemplateOutputPath = path.join(projectDirectory, 'build', CLOUDFORMATION_FILE_NAME);
            fs.writeFileSync(cloudFormationTemplateOutputPath, JSON.stringify(templateCopy, null, 4));
            parametersInputPath = path.join(projectDirectory, PARAMETERS_FILE_NAME);
            fs.writeFileSync(parametersInputPath, JSON.stringify(filteredParameterValues, null, 4));
            // If the resolvers & stacks directories do not exist, create them.
            initStacksAndResolversDirectories(projectDirectory);
            return [2 /*return*/];
        });
    });
}
function initStacksAndResolversDirectories(directory) {
    var resolverRootPath = path.normalize(directory + "/resolvers");
    if (!fs.existsSync(resolverRootPath)) {
        fs.mkdirSync(resolverRootPath);
    }
    var stackRootPath = path.normalize(directory + "/stacks");
    if (!fs.existsSync(stackRootPath)) {
        fs.mkdirSync(stackRootPath);
    }
}
var readDir = function (dir) { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {
    switch (_a.label) {
        case 0: return [4 /*yield*/, promisify(fs.readdir, dir)];
        case 1: return [2 /*return*/, _a.sent()];
    }
}); }); };
var readFile = function (p) { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {
    switch (_a.label) {
        case 0: return [4 /*yield*/, promisify(fs.readFile, p)];
        case 1: return [2 /*return*/, _a.sent()];
    }
}); }); };
var lstat = function (dir) { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {
    switch (_a.label) {
        case 0: return [4 /*yield*/, promisify(fs.lstat, dir)];
        case 1: return [2 /*return*/, _a.sent()];
    }
}); }); };
var exists = function (p) { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {
    switch (_a.label) {
        case 0: return [4 /*yield*/, new Promise(function (res) { return fs.exists(p, function (e) { return res(e); }); })];
        case 1: return [2 /*return*/, _a.sent()];
    }
}); }); };
var unlink = function (p) { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {
    switch (_a.label) {
        case 0: return [4 /*yield*/, new Promise(function (res, rej) { return fs.unlink(p, function (e) { return e ? rej(e) : res(); }); })];
        case 1: return [2 /*return*/, _a.sent()];
    }
}); }); };
var rmdir = function (p) { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {
    switch (_a.label) {
        case 0: return [4 /*yield*/, new Promise(function (res, rej) { return fs.rmdir(p, function (e) { return e ? rej(e) : res(); }); })];
        case 1: return [2 /*return*/, _a.sent()];
    }
}); }); };
function promisify(fn, a) {
    return new Promise(function (res, rej) {
        fn(a, function (err, d) {
            err ? rej(err) : res(d);
        });
    });
}
//# sourceMappingURL=amplifyUtils.js.map